{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "dataset = pd.read_csv('E:\\Research\\Datasets\\WSO2/dataset2.csv')\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change feature names for ease of use\n",
    "header_map = {\n",
    "    \"How likely are you to recommend WSO2 to a friend_ or colleague on a scale from 0 to 10? [0 being not at all likely and 10 being extremely likely]\":'likely_to_recomend',\n",
    "    \"How satisfied are you with the support given by the WSO2 team?\":'satisfaction',\n",
    "    \"Which response best captures the main impact of our product?\":'product_impact',\n",
    "    \"How responsive have we been to your questions or concerns about our products?\":'responsiveness'\n",
    "}\n",
    "\n",
    "dataset.rename(columns=header_map,inplace=True)\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nps_dataset = dataset[['ResponseID','likely_to_recomend','satisfaction','responsiveness','product_impact']]\n",
    "nps_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nps_dataset['satisfaction'].unique(),'\\n',nps_dataset['responsiveness'].unique(),'\\n',nps_dataset['product_impact'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding on features\n",
    "h1_map = {\"Excellent\":5,\"Good\":4,\"Okay\":3,\"Bad\":2,\"Terrible\":1}\n",
    "h2_map = {\"Excellent\":4,\"Good\":3,\"OK\":2,\"Slow\":1}\n",
    "h3_map = {\"Many of the above\":9,\"High Quality\":8,\"Scalable\":7,\"Value for Money\":6,\"Useful\":5,\"Reliable\":4,\"Secure\":3,\"Unique\":2,\"None of the above\":1}\n",
    "\n",
    "# --- satisfaction ----\n",
    "nps_dataset['encoded_satisfaction'] = nps_dataset.satisfaction.map(h1_map)\n",
    "nps_dataset = nps_dataset.drop(['satisfaction'],axis=1)\n",
    "\n",
    "# --- responsiveness ---\n",
    "nps_dataset['encoded_responsiveness'] = nps_dataset.responsiveness.map(h2_map)\n",
    "nps_dataset = nps_dataset.drop(['responsiveness'],axis=1)\n",
    "\n",
    "# --- product_impact ----\n",
    "nps_dataset['encoded_product_impact'] = nps_dataset.product_impact.map(h3_map)\n",
    "nps_dataset = nps_dataset.drop(['product_impact'],axis=1)\n",
    "\n",
    "nps_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate score\n",
    "# manual_score_dataset= nps_dataset.drop(['Clusters'],axis=1)\n",
    "manual_score_dataset= nps_dataset\n",
    "\n",
    "health_scores = []\n",
    "features = ['likely_to_recomend','encoded_satisfaction','encoded_responsiveness']\n",
    "weights = [50,30,20]\n",
    "\n",
    "# normalize\n",
    "for feature,weight in zip(features,weights):\n",
    "    if abs(manual_score_dataset[feature].max()) == 0:\n",
    "        continue\n",
    "    manual_score_dataset[feature] = (manual_score_dataset[feature]/manual_score_dataset[feature].max())*weight\n",
    "\n",
    "# calculate health score\n",
    "manual_score_dataset['health_score'] = (manual_score_dataset['likely_to_recomend'] + manual_score_dataset['encoded_satisfaction'] + manual_score_dataset['encoded_responsiveness'] )*100/sum(weights)\n",
    "\n",
    "# manual_score_dataset['health_score'] = health_scores\n",
    "manual_score_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add health score to original dataset\n",
    "main_dataset = pd.read_csv('E:\\Research\\Datasets\\WSO2/dataset2.csv')\n",
    "\n",
    "\n",
    "# change feature names for ease of use\n",
    "header_map = {\n",
    "    \"How likely are you to recommend WSO2 to a friend_ or colleague on a scale from 0 to 10? [0 being not at all likely and 10 being extremely likely]\":'likely_to_recomend',\n",
    "    \"How satisfied are you with the support given by the WSO2 team?\":'satisfaction',\n",
    "    \"Which response best captures the main impact of our product?\":'product_impact',\n",
    "    \"How responsive have we been to your questions or concerns about our products?\":'responsiveness'\n",
    "}\n",
    "\n",
    "main_dataset.rename(columns=header_map,inplace=True)\n",
    "\n",
    "healthscore_main_dataset = pd.merge(main_dataset,manual_score_dataset[['ResponseID','health_score']],on='ResponseID',how='left')\n",
    "healthscore_main_dataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns\n",
    "\n",
    "regressor_dataset = healthscore_main_dataset[['ResponseID','likely_to_recomend','satisfaction','responsiveness','product_impact','Country_with_city','completion','Sales Region','Sub Region','Account Name','Account Manager Name','Segment','health_score']]\n",
    "regressor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the data\n",
    "\n",
    "# ordinal encoding on ordinal features\n",
    "h1_map = {\"Excellent\":5,\"Good\":4,\"Okay\":3,\"Bad\":2,\"Terrible\":1}\n",
    "h2_map = {\"Excellent\":4,\"Good\":3,\"OK\":2,\"Slow\":1}\n",
    "h3_map = {\"Many of the above\":9,\"High Quality\":8,\"Scalable\":7,\"Value for Money\":6,\"Useful\":5,\"Reliable\":4,\"Secure\":3,\"Unique\":2,\"None of the above\":1}\n",
    "\n",
    "# --- satisfaction ----\n",
    "regressor_dataset['encoded_satisfaction'] = regressor_dataset.satisfaction.map(h1_map)\n",
    "regressor_dataset = regressor_dataset.drop(['satisfaction'],axis=1)\n",
    "\n",
    "# --- responsiveness ---\n",
    "regressor_dataset['encoded_responsiveness'] = regressor_dataset.responsiveness.map(h2_map)\n",
    "regressor_dataset = regressor_dataset.drop(['responsiveness'],axis=1)\n",
    "\n",
    "# --- product_impact ----\n",
    "regressor_dataset['encoded_product_impact'] = regressor_dataset.product_impact.map(h3_map)\n",
    "regressor_dataset = regressor_dataset.drop(['product_impact'],axis=1)\n",
    "\n",
    "\n",
    "# label encoding for categorical features\n",
    "from sklearn import preprocessing \n",
    "\n",
    "features = ['Country_with_city','Sub Region','Account Name','Account Manager Name','Segment','Sales Region','completion']\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "for feature in features:\n",
    "    regressor_dataset[feature] = label_encoder.fit_transform(regressor_dataset[feature])\n",
    "\n",
    "regressor_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_dataset.drop(['ResponseID','likely_to_recomend','encoded_responsiveness','encoded_satisfaction'],axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save regressor dataset\n",
    "regressor_dataset.to_csv('E:\\Research\\Datasets\\WSO2\\Healthscore_dataset\\Regressor_Data/regressor_dataset3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(regressor_dataset['health_score'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing a model for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso,BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffle the dataset\n",
    "X = regressor_dataset.drop(['ResponseID','health_score','likely_to_recomend','encoded_responsiveness','encoded_satisfaction','Country_with_city','Account Name'],axis=1)\n",
    "y = regressor_dataset[['health_score']]\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out different models\n",
    "\n",
    "# List of regression models to try\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(),\n",
    "    'XGBRegressor': xgb.XGBRFRegressor(objective ='reg:squarederror'),\n",
    "    'Baysian Regressor':BayesianRidge()\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{model_name}: Mean Squared Error = {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to mse values above GradientBoostingRegressor give the best value. So Let use Linear Regression for our regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "\n",
    "X,y = shuffle(X,y,random_state=40)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "print('MSE score  : ',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import pickle\n",
    "\n",
    "file = 'E:\\Research\\Models/GradientBoostingRegressorModel3.pkl'\n",
    "with open(file, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

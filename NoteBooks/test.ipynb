{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input dataset\n",
    "input_data = pd.read_csv('E:/Research/WebApp/input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "rfc = joblib.load('E:/Research/Models/Classifiers/random_forest_classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the headers to ease of use\n",
    "header_map = {\n",
    "    \"How likely are you to recommend WSO2 to a friend_ or colleague on a scale from 0 to 10? [0 being not at all likely and 10 being extremely likely]\":'likely_to_recomend',\n",
    "    \"How satisfied are you with the support given by the WSO2 team?\":'satisfaction',\n",
    "    \"Which response best captures the main impact of our product?\":'product_impact',\n",
    "    \"How responsive have we been to your questions or concerns about our products?\":'responsiveness'\n",
    "}\n",
    "input_data.rename(columns=header_map,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['Sub Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the necessary features\n",
    "input_data = input_data[['ResponseID','likely_to_recomend','satisfaction','responsiveness','product_impact','Account Name','Sales Region']]\n",
    "input_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding on features\n",
    "h1_map = {\"Excellent\":5,\"Good\":4,\"Okay\":3,\"Bad\":2,\"Terrible\":1}\n",
    "h2_map = {\"Excellent\":4,\"Good\":3,\"OK\":2,\"Slow\":1}\n",
    "h3_map = {\"Many of the above\":9,\"High Quality\":8,\"Scalable\":7,\"Value for Money\":6,\"Useful\":5,\"Reliable\":4,\"Secure\":3,\"Unique\":2,\"None of the above\":1}\n",
    "# --- satisfaction ----\n",
    "input_data['encoded_satisfaction'] = input_data.satisfaction.map(h1_map)\n",
    "input_data = input_data.drop(['satisfaction'],axis=1)\n",
    "# --- responsiveness ---\n",
    "input_data['encoded_responsiveness'] = input_data.responsiveness.map(h2_map)\n",
    "input_data = input_data.drop(['responsiveness'],axis=1)\n",
    "# --- product_impact ----\n",
    "input_data['encoded_product_impact'] = input_data.product_impact.map(h3_map)\n",
    "input_data = input_data.drop(['product_impact'],axis=1)\n",
    "\n",
    "# one-hot encoding for string values\n",
    "encoded_new_d = pd.get_dummies(input_data,columns=['encoded_product_impact'],dtype=int)\n",
    "input_data = encoded_new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "input = input_data.drop(['ResponseID','Account Name','Sales Region'],axis=1)\n",
    "y_pred = rfc.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prediction to dataset\n",
    "input_data['-        Health        -'] = y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = input_data[['Account Name','-        Health        -','Sales Region']]\n",
    "def aggregate_Health(output_data):\n",
    "    output = output_data\n",
    "    health_val_map = {\"Good\":4,\"Need improvement\":3,\"Need more attention\":2,\"At risk\":1}\n",
    "    output['-        Health        -'] = output['-        Health        -'].map(health_val_map)\n",
    "\n",
    "    account_names = output['Account Name'].unique()  # unique account names\n",
    "    df_temp = pd.DataFrame()       # create an empty dataframe\n",
    "    health = []                    # create empty array to assign health\n",
    "    sales_region = []\n",
    "\n",
    "\n",
    "    for account in account_names:\n",
    "        mean_of_health = output[output['Account Name']==account]['-        Health        -'].mean()\n",
    "        mean_of_health = round(mean_of_health,0)\n",
    "        health.append(mean_of_health)\n",
    "\n",
    "        region = output[output['Account Name'] == account]['Sales Region'].unique()[0]\n",
    "        sales_region.append(region)\n",
    "\n",
    "    df_temp['Account Name'] = account_names\n",
    "    df_temp['-        Health        -'] = health\n",
    "    df_temp['Sales_Region'] = sales_region\n",
    "\n",
    "\n",
    "    output = df_temp\n",
    "    health_val_map = {4:\"Good\",3:\"Need improvement\",2:\"Need more attention\",1:\"At risk\"}\n",
    "    output['-        Health        -'] = output['-        Health        -'].map(health_val_map)\n",
    "    return output\n",
    "\n",
    "a= aggregate_Health(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Sales_Region'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Health Score pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input dataset\n",
    "input = pd.read_csv('E:/Research/WebApp/input.csv')\n",
    "input_data = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the headers to ease of use\n",
    "header_map = {\n",
    "    \"How likely are you to recommend WSO2 to a friend_ or colleague on a scale from 0 to 10? [0 being not at all likely and 10 being extremely likely]\":'likely_to_recomend',\n",
    "    \"How satisfied are you with the support given by the WSO2 team?\":'satisfaction',\n",
    "    \"Which response best captures the main impact of our product?\":'product_impact',\n",
    "    \"How responsive have we been to your questions or concerns about our products?\":'responsiveness'\n",
    "}\n",
    "input_data.rename(columns=header_map,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoding on features\n",
    "h1_map = {\"Excellent\":5,\"Good\":4,\"Okay\":3,\"Bad\":2,\"Terrible\":1}\n",
    "h2_map = {\"Excellent\":4,\"Good\":3,\"OK\":2,\"Slow\":1}\n",
    "h3_map = {\"Many of the above\":9,\"High Quality\":8,\"Scalable\":7,\"Value for Money\":6,\"Useful\":5,\"Reliable\":4,\"Secure\":3,\"Unique\":2,\"None of the above\":1}\n",
    "# --- satisfaction ----\n",
    "input_data['encoded_satisfaction'] = input_data.satisfaction.map(h1_map)\n",
    "input_data = input_data.drop(['satisfaction'],axis=1)\n",
    "# --- responsiveness ---\n",
    "input_data['encoded_responsiveness'] = input_data.responsiveness.map(h2_map)\n",
    "input_data = input_data.drop(['responsiveness'],axis=1)\n",
    "# --- product_impact ----\n",
    "input_data['encoded_product_impact'] = input_data.product_impact.map(h3_map)\n",
    "input_data = input_data.drop(['product_impact'],axis=1)\n",
    "\n",
    "# # one-hot encoding for string values\n",
    "# encoded_new_d = pd.get_dummies(input_data,columns=['encoded_product_impact'],dtype=int)\n",
    "# input_data = encoded_new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding for categorical features\n",
    "from sklearn import preprocessing \n",
    "\n",
    "features = ['Sub Region','Account Name','Account Manager Name','Segment','Sales Region','completion']\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "for feature in features:\n",
    "    input_data[feature] = label_encoder.fit_transform(input_data[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "X = input_data[['completion', 'Sales Region', 'Sub Region', 'Account Manager Name','Segment', 'encoded_product_impact']]\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# load the model\n",
    "import pickle\n",
    "filename = 'E:\\Research\\Models/GradientBoostingRegressorModel3.pkl'\n",
    "model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# predict \n",
    "y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign health score to dataset \n",
    "healthscore_dataset = input_data[['ResponseID','completion', 'Sales Region', 'Sub Region', 'Account Manager Name','Segment', 'encoded_product_impact']]\n",
    "healthscore_dataset.dropna(inplace=True)\n",
    "healthscore_dataset['Health_Score'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthscore_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input[['ResponseID','Account Name','Account Manager Name','Sales Region','ARR','dateTime']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset with health\n",
    "d1 = input[['ResponseID','Account Name','Account Manager Name','Sales Region','ARR','dateTime']]\n",
    "d2 = healthscore_dataset[['ResponseID','Health_Score']]\n",
    "\n",
    "final_dataset = pd.merge(d2,d1,how='right',on='ResponseID')\n",
    "final_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
